services:
  # VLM for Traffic Agent B
  vlm-openvino-serving-b:
    image: intel/vlm-openvino-serving:1.2.2
    ports:
      - "9766:8000"
    ipc: host
    networks:
      - scenescape
    environment:
      no_proxy_env: ${no_proxy_env},${HOST_IP}
      no_proxy: ${no_proxy_env},${HOST_IP}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      VLM_MODEL_NAME: ${VLM_MODEL_NAME:-Qwen/Qwen2.5-VL-3B-Instruct}
      VLM_COMPRESSION_WEIGHT_FORMAT: ${VLM_COMPRESSION_WEIGHT_FORMAT:-int4}
      VLM_DEVICE: ${VLM_DEVICE:-CPU}
      VLM_SEED: ${VLM_SEED:-42}
      WORKERS: ${VLM_WORKERS:-1}
      VLM_MAX_COMPLETION_TOKENS: ${VLM_MAX_COMPLETION_TOKENS:-1500}
      HUGGINGFACE_TOKEN: ${HUGGINGFACE_TOKEN}
      OV_CONFIG: ${OV_CONFIG}
      VLM_LOG_LEVEL: ${VLM_LOG_LEVEL:-info}
      OPENVINO_LOG_LEVEL: ${VLM_OPENVINO_LOG_LEVEL:-1}
      VLM_ACCESS_LOG_FILE: ${VLM_ACCESS_LOG_FILE:-/dev/null}
    restart: unless-stopped
    devices:
      - /dev/dri:/dev/dri
    group_add:
      - ${USER_GROUP_ID:-1000}
      - ${VIDEO_GROUP_ID:-44}
      - ${RENDER_GROUP_ID:-109}
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 60
      start_period: 10s
    volumes:
      - ov-models-b:/root/.cache/huggingface
      - ov-models-b:/app/ov-model

  # Traffic Intelligence B
  traffic-intelligence-b:
    build:
      context: ../../smart-traffic-intersection-agent/src/traffic-intelligence
      dockerfile: Dockerfile
    image: ${REGISTRY:-}traffic-intelligence:${TAG:-latest}
    ports:
      - "8083:8081"
      - "7862:7860"
    networks:
      - scenescape
    depends_on:
      vlm-openvino-serving-b:
        condition: service_healthy
    environment:
      TRAFFIC_INTELLIGENCE_HOST: 0.0.0.0
      TRAFFIC_INTELLIGENCE_PORT: 8081
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      TRAFFIC_INTELLIGENCE_UI_PORT: 7860
      USE_API: "true"
      API_URL: http://localhost:8081/api/v1/traffic/current
      REFRESH_INTERVAL: ${REFRESH_INTERVAL:-15}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      no_proxy: ${no_proxy_env},.scenescape.intel.com,${HOST_IP},broker.scenescape.intel.com,vlm-openvino-serving-b
      NO_PROXY: ${no_proxy_env},.scenescape.intel.com,${HOST_IP},broker.scenescape.intel.com,vlm-openvino-serving-b
      HTTP_PROXY: ${http_proxy}
      HTTPS_PROXY: ${https_proxy}
      MQTT_HOST: ${MQTT_HOST:-broker.scenescape.intel.com}
      MQTT_PORT: ${MQTT_PORT:-1883}
      INTERSECTION_NAME: ${INTERSECTION_NAME:-Intersection-B}
      INTERSECTION_LATITUDE: ${INTERSECTION_LATITUDE:-37.7049108}
      INTERSECTION_LONGITUDE: ${INTERSECTION_LONGITUDE:--121.9096158}
      WEATHER_MOCK: ${WEATHER_MOCK:-true}
      VLM_MODEL: ${VLM_MODEL_NAME:-Qwen/Qwen2.5-VL-3B-Instruct}
      HIGH_DENSITY_THRESHOLD: ${HIGH_DENSITY_THRESHOLD:-10}
      # Planner integration
      ROUTE_PLANNER_URL: http://ai-route-planner:7860/plan-route
      INTERSECTION_ID: B
    volumes:
      - ../../smart-traffic-intersection-agent/src/traffic-intelligence/config:/app/config:ro
      - traffic-intelligence-data-b:/app/data
    secrets:
      - source: root-cert
        target: /app/secrets/certs/scenescape-ca.pem
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/health || exit 1"]
      interval: ${HEALTH_CHECK_INTERVAL:-30s}
      timeout: ${HEALTH_CHECK_TIMEOUT:-10s}
      retries: ${HEALTH_CHECK_RETRIES:-3}
      start_period: ${HEALTH_CHECK_START_PERIOD:-10s}
    restart: unless-stopped

secrets:
  root-cert:
    file: /home/intel/mkumari/edge-ai-suites/metro-ai-suite/metro-vision-ai-app-recipe/smart-intersection/src/secrets/certs/scenescape-ca.pem

volumes:
  ov-models-b:
  traffic-intelligence-data-b:

networks:
  scenescape:
    external: true
    name: metro-vision-ai-app-recipe_scenescape
